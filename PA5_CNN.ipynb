{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Ethan Greenwood\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA5\n",
    "\n",
    "## Intro to Convolutional Neural Nets with Keras\n",
    "\n",
    "Contest on Cat/Dog classification. \n",
    "\n",
    "Due F, 7/30/2021, 5pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contest\n",
    "\n",
    "Besides the ~20k train/test images that we load below, there are ~5,000 more unseen/hidden cat/dog images in a private folder. \n",
    "\n",
    "Train a CNN model of your own design, tune it, (cross-validate it if you want!) until you are satisfied with its performance.\n",
    "\n",
    "I will run your saved models on this competition dataset and let you know how well your model fares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part: You must **create your own model** such as the VGG example or a smaller one of your own design, like you did in 'Lab Classification with Keras'! \n",
    "\n",
    "\n",
    "### Important: Your  model has to be named `comp_model` \n",
    "\n",
    "``` python\n",
    "comp_model = myNN(X_train)\n",
    "```\n",
    "\n",
    "If your model name is incorrect, my call will fail and so may you! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d71c342e4624dfa3a1df4a65c6b8644",
     "grade": false,
     "grade_id": "cell-20a94lkm51bca15f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## What can I use?\n",
    "- Your code can use feature engineering, normalization or other common tricks\n",
    "- You can use Dense, Conv2D or similar layers in Keras \n",
    "- You can use dropout, normalization, etc.\n",
    "- You can (and should!) plot your history and observe your model's behaviour. \n",
    "- You can choose your favorite 'optimizer' or 'loss' functions.\n",
    "- Your 'metrics' HAS to be:  `metrics = ['accuracy','mae']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "289631525b99ad119f1572bb6d02b0df",
     "grade": false,
     "grade_id": "cell-20a9jik9m51bca15f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Comments\n",
    "- **Results**: Validation alone is not enough for this assignment as some parts are manually graded. For me to able to view your results, you need to ensure that your notebook runs. One way to test is to click: `Kernel`->`Restart & Run All` and verify that all cells execute without errors. \n",
    "- **Runtime**: Each notebook has a runtime limit. Your submitted notebook should execute in under a min. Thus, if you are using iterative algos, similar to scikit's GridSearch, comment them out before submitting your notebook. For instance, you can hard code the best coefs returned by such algorithms and comment out the search to save execution time.\n",
    "- **Randomness**: if you are using an algo that depends on random state, make sure it is reproduceable. For instance, set the random seed so that your model behaves similary when I execute it.  You could also [save your model and load it](https://www.tensorflow.org/guide/keras/save_and_serialize) to get around this. \n",
    "- Above also means that you can comment out your training code to save execution time and avoid the randomness issue. MAke sure to load your model as 'comp_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "- Name your trained Keras model as `comp_model` \n",
    "- Your 'metrics' HAS to be:  `metrics = ['accuracy','mae']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14967, 50, 50, 1) (4990, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the train/test data:\n",
    "import numpy as np\n",
    "path = '/home/memo/public/eaix/'\n",
    "\n",
    "X_train = np.load(path+'X_train.npy')\n",
    "X_test = np.load(path+'X_test.npy')\n",
    "y_train = np.load(path+'y_train.npy')\n",
    "y_test = np.load(path+'y_test.npy')\n",
    "print(X_train.shape, X_test.shape) #should be (14967, 50, 50, 1) (4990, 50, 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "#DONT KNOW IF JUST ME BUT IMPORTS FAIL ON FIRST ATTEMPT\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "09ee51a665c4b087017f280cc56fd213",
     "grade": true,
     "grade_id": "cell-5d8459d3a6d6ba5d",
     "locked": false,
     "points": 50,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def make_model():\n",
    "    # Add layers in given order\n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(10, (3,3), input_shape=(50,50,1), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(20, (3,3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "85aadb3af7dfe77acf439f3dd3c7a67d",
     "grade": true,
     "grade_id": "cell-0fd7a62ff7c436de",
     "locked": false,
     "points": 50,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#LAST RESULT:\n",
    "#4990/4990 [==============================] - 1s 284us/step\n",
    "#*** Test *** \n",
    "#NN Test MAE:  0.331348180770874\n",
    "#NN Test ACC:  0.6733466982841492\n",
    "\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14967/14967 [==============================] - 15s 1ms/step - loss: 0.0276 - accuracy: 0.9925 - mae: 0.0180\n",
      "Epoch 2/5\n",
      "14967/14967 [==============================] - 14s 937us/step - loss: 0.0036 - accuracy: 0.9995 - mae: 0.0029\n",
      "Epoch 3/5\n",
      "14967/14967 [==============================] - 15s 975us/step - loss: 0.0023 - accuracy: 0.9998 - mae: 0.0012\n",
      "Epoch 4/5\n",
      "14967/14967 [==============================] - 14s 962us/step - loss: 5.5299e-04 - accuracy: 0.9999 - mae: 4.0796e-04\n",
      "Epoch 5/5\n",
      "14967/14967 [==============================] - 14s 962us/step - loss: 0.0170 - accuracy: 0.9950 - mae: 0.0070\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-247393cc60d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcomp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# History object is a dictionary with keys.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloss_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot history: Sample code\n",
    "#ne is number of epochs to plot. Update it! \n",
    "ne = 5\n",
    "batch=15\n",
    "comp_model.fit(X_train, y_train, epochs=ne, batch_size=batch, verbose=1)\n",
    "# History object is a dictionary with keys. \n",
    "hd = history.history\n",
    "\n",
    "loss_tr = hd['accuracy']\n",
    "loss_va = hd['val_accuracy']\n",
    "epochs = range(0, ne) #ne is number of epochs. Set it! \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.plot(epochs, loss_tr, '-.o', label='Training Acc')\n",
    "plt.plot(epochs, loss_va, 'r', label='Validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap it up\n",
    "\n",
    "Once you are happy with your model, you can comment out your training code (model.fit() ) and SAVE your model: \n",
    "\n",
    "\n",
    "How to save/load your model: https://www.tensorflow.org/guide/keras/save_and_serialize\n",
    "\n",
    "Pseudocode to save/load and test a Keras NN name 'mymodel': \n",
    "``` python\n",
    "model.save('mymodel') #save your model\n",
    "comp_model = load_model('mymodel') #load it as desired name\n",
    "#Comment out: model.fit, history and model.save() if load works.\n",
    "#Evaluate loaded models performance on test data:\n",
    "nnmse, nnacc, nnmae = comp_model.evaluate(X_test, y_test, verbose = 1)\n",
    "print('*** Test *** ')\n",
    "print('NN Test MAE: ', nnmae)\n",
    "print('NN Test ACC: ', nnacc)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4990/4990 [==============================] - 1s 264us/step\n",
      "*** Test *** \n",
      "NN Test MAE:  0.331348180770874\n",
      "NN Test ACC:  0.6733466982841492\n"
     ]
    }
   ],
   "source": [
    "comp_model.save('mymodel') #save your model\n",
    "#comp_model = load_model('mymodel') #load it as desired name\n",
    "#Comment out: model.fit, history and model.save() if load works.\n",
    "#Evaluate loaded models performance on test data:\n",
    "nnmse, nnacc, nnmae = comp_model.evaluate(X_test, y_test, verbose = 1)\n",
    "print('*** Test *** ')\n",
    "print('NN Test MAE: ', nnmae)\n",
    "print('NN Test ACC: ', nnacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "72ec5986edf28571d9e5511aba2cdb74",
     "grade": false,
     "grade_id": "cell-0399b84769f5fb0e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Performance on hidden data\n",
    "\n",
    "You shouldn't be able to run the following cells as these are hidden files. But, I'll run them to evaluate your models performance on this data. \n",
    "\n",
    "Your model must be saved as `comp_model` for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a5ed3c61ad251cd3e911993a285dc2a",
     "grade": false,
     "grade_id": "cell-4916d7a141213f7e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/memo/private/X_val.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9e72b9ad0a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read hidden data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Note this data is NOT visible to you.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/memo/private/X_val.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/memo/private/y_val.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/memo/private/X_val.npy'"
     ]
    }
   ],
   "source": [
    "#read hidden data\n",
    "#Note this data is NOT visible to you. \n",
    "X_val =  np.load('/home/memo/private/X_val.npy')\n",
    "y_val =  np.load('/home/memo/private/y_val.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28454e89d05c50a3eea8a35183ec51ac",
     "grade": false,
     "grade_id": "cell-a95f9354ff69cf7a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Competition data. You can't run this.\n",
    "nnloss, nnacc, nnmae = comp_model.evaluate(X_val, y_val, verbose = 1)\n",
    "#final score on hidden dataset:\n",
    "print(\"Competition accuracy is %.2f\" % (nnacc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
